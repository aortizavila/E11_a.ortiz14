{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "## Car Price Prediction\n",
    "\n",
    "Predict if the price of a car is low or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/dataTrain_carListings.zip')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.1\n",
    "\n",
    "Estimate a Decision Tree Classifier Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ginni de cada rama que parti. Gini muestra la diferencia entre las dos clases\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    #la ganancia media en gini inicial mas la suma ponderada de gini lado izq y gini lado derecho. Porcentaje hay en la izq y hay en la derecha\n",
    "    # Por que se pondera? Sino se pondera se podría llegar a tener una partición que envíe al izquierdo ej. \n",
    "    # yo quiero generar ramas que dejen en un lado todos los unos y en otro todos los ceros. Es mejor el valor alto de gini.\n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    # Calculo todos los posibles splits que se van a utilizar\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        # Guardo los mejores split en j\n",
    "        # Para saber que no sigo partiendo mas, miro la mínima ganancia\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    # devulve la variable, la ganancia y el corte\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    # la predicción en ese nodo (requiree el promedio ajustado por laplace)\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    #La probabilidad es la proporción del uno u otro\n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=-1)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    #Selecciono la máxima ganancia\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    # PArto el x del lado derecho e izquierdo\n",
    "    # split = -1, es el criterio de parada. (split es el indice de la variable)\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    tree['gain'] = gain\n",
    "\n",
    "    # Next iteration to each split\n",
    "    # PAra cada partición se vuelve a iterar toda la función\n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "accuracy_scores = []\n",
    "for depth in max_depth_range:\n",
    "    tree=tree_grow(X_train, y_train, level=3, min_gain=0.001, max_depth=depth, num_pct=10)\n",
    "    y_pred=tree_predict(X_test, tree)\n",
    "    accuracy_scores.append(metrics.accuracy_score(y_pred, y_test))\n",
    "    \n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8771889400921659, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(accuracy_scores, max_depth_range))[::-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.2\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Número de árboles\n",
    "n_estimators = 10\n",
    "\n",
    "# Semilla\n",
    "np.random.seed(123)\n",
    "\n",
    "# Ejemplos de muestra\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Crear el muestreo aleatorio(will be used to select rows from the DataFrame)\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los árboles\n",
    "predic = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    predic[i] = tree_predict(X_test, tree_grow(X_train.iloc[samples[i]], y_train.iloc[samples[i]], level=0, min_gain=0.001, max_depth=i, num_pct=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = (predic.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8939\n",
      "Accuracy:  0.87\n"
     ]
    }
   ],
   "source": [
    "#Se seleccionan las predicciones que dieron mas de 50% como positiva.\n",
    "\n",
    "from sklearn import metrics\n",
    "print('F1 score: ',round(metrics.f1_score(predic, y_test),4))\n",
    "print('Accuracy: ',round(metrics.accuracy_score(predic, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.3\n",
    "\n",
    "Implement the variable max_features on the Decision Tree Classifier created in 11.1.\n",
    "\n",
    "Compare the impact in the results by varing the parameter max_features\n",
    "\n",
    "#Seleccionar las variables aleatorias por nodo\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10,max_features=len(X.columns)):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    # devulve la variable, la ganancia y el corte\n",
    "    j, split, gain = best_split(X, y, num_pct,max_features)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    # la predicción en ese nodo (requiree el promedio ajustado por laplace)\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    #La probabilidad es la proporción del uno u otro\n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=-1)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    #Selecciono la máxima ganancia\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    # PArto el x del lado derecho e izquierdo\n",
    "    # split = -1, es el criterio de parada. (split es el indice de la variable)\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    tree['gain'] = gain\n",
    "   \n",
    "    # Next iteration to each split\n",
    "    # PAra cada partición se vuelve a iterar toda la función\n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct,max_features=max_features)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct,max_features=max_features)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10,max_features=len(X.columns)):\n",
    "   \n",
    "    Xa = X.sample(max_features, axis=1)\n",
    "    \n",
    "    features = range(Xa.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    # Calculo todos los posibles splits que se van a utilizar\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(Xa.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        # Guardo los mejores split en j\n",
    "        # Para saber que no sigo partiendo mas, miro la mínima ganancia\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(Xa.iloc[:, j], y, split)\n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "  \n",
    "    col = Xa.columns[best_split[0]]\n",
    "    best_split[0] = X.columns.get_loc(col)\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8566820276497696\n",
      "0.8787524366471735\n"
     ]
    }
   ],
   "source": [
    "#X_train\n",
    "tree=tree_grow(X_train, y_train, level=3, min_gain=0.001, max_depth=6, num_pct=10,max_features=5)\n",
    "#tree\n",
    "y_pred=tree_predict(X_test, tree)\n",
    "   \n",
    "print(metrics.accuracy_score(y_pred, y_test))\n",
    "print(metrics.f1_score(y_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.4\n",
    "\n",
    "Random forest manual\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers with `max_features = log(n_features)`\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "\n",
    "# Semilla\n",
    "np.random.seed(123)\n",
    "\n",
    "# Ejemplos de muestra\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Crear el muestreo aleatorio(will be used to select rows from the DataFrame)\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n_features=0\n",
    "n_features = X_train.shape[1]\n",
    "predic = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "\n",
    "for i in range(10):\n",
    "    predic[i] = tree_predict(X_test, tree_grow(X_train.iloc[samples[i]], y_train.iloc[samples[i]], level=0, min_gain=0.001, max_depth=i, num_pct=10,max_features=int(math.log(n_features))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = (predic.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8785\n",
      "Accuracy:  0.8424\n"
     ]
    }
   ],
   "source": [
    "print('F1 score: ',round(metrics.f1_score(predic, y_test),4))\n",
    "print('Accuracy: ',round(metrics.accuracy_score(predic, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.5\n",
    "\n",
    "Utilice sklearn\n",
    "\n",
    "Using sklearn, train a RandomForestClassifier\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9019\n",
      "Accuracy:  0.8811\n"
     ]
    }
   ],
   "source": [
    "#max_features='auto' elige de manera aleatoria cada variable\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=6, n_estimators = 10,max_features=5,random_state=123)\n",
    "X= clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('F1 score: ',round(metrics.f1_score(y_pred, y_test),4))\n",
    "print('Accuracy: ',round(metrics.accuracy_score(y_pred, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.6\n",
    "\n",
    "Utilice sklearn\n",
    "\n",
    "Find the best parameters of the RandomForestClassifier (max_depth, max_features, n_estimators)\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8859240894046355 Max depth:  8 Estimadores:  15 Feature:  2 Semilla:  41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "max_depth_range = range(1, 12)\n",
    "estimator_range = range(1, 16, 2)\n",
    "feature_range = range(1,X_train.shape[1])\n",
    "semilla = range(1,101,10)\n",
    "accuracy_scores = []\n",
    "a= 0\n",
    "md = 0\n",
    "et = 0\n",
    "ft = 0\n",
    "sm = 0\n",
    "for max_depth in max_depth_range: \n",
    "    for estimator in estimator_range:\n",
    "        for feature in feature_range:\n",
    "            for sem in semilla:\n",
    "                clf = RandomForestClassifier(max_depth=max_depth, n_estimators = estimator,max_features=feature,random_state=sem)\n",
    "                accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "                ac=cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "                if ac >= a:\n",
    "                    a=ac\n",
    "                    md = max_depth\n",
    "                    et = estimator\n",
    "                    ft = feature\n",
    "                    sm = sem\n",
    "print('Accuracy: ',  a,'Max depth: ',md, 'Estimadores: ',et, 'Feature: ',ft,'Semilla: ',sm)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
